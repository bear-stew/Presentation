# Presentation


 | Paper | Conference | Year | Task | Presenter | Presentation | References |
 |:---|:---:|:---:|:---:|:---:|:---:|:---:|
 | [Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html) | NeurIPS | '17 | NLP | μ„λ™μ£Ό | [π“](data/Attention%20is%20All%20You%20Need.pdf)|
 | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)](https://arxiv.org/abs/2010.11929) | ICLR | '21 | CV | κΉ€λ‚ν› | [π“](data/presentation_vit.pdf) | 
 | [BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805v2) | NAACL | '19 | NLP | μ¤μ„Έν™ |
 | [GPT: Improving Language Understanding by Generative Pre-Training](https://www.mikecaptain.com/resources/pdf/GPT-1.pdf) |  | '18 | NLP | μ΄ν•μ¤€ |
 | [Pointer Networks](https://proceedings.neurips.cc/paper_files/paper/2015/hash/29921001f2f04bd3baee84a12e98098f-Abstract.html) | NeurIPS | '15 | | κΉ€ν„μ° |
 | [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971) |  | '23 | NLP | κΉ€μ | [π“](data/LLaMA.pdf) |
 | [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/pdf/2104.09864&hl=ja&sa=X&ei=5B0dZcHLGJ2h6rQPweSL0A0&scisig=AFWwaebUGjvb4JBysy2Z1l7aHWfJ&oi=scholarr) |  | '21 | NLP | μ¤μ„Έν™ |
 | [Donut: Document Understanding Transformer without OCR](https://sangdooyun.github.io/data/kim2021donut.pdf) | ECCV | '22 | CV | κΉ€λ‚ν› | [π“](data/presentation_donut.pdf) | 
 | [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper) | ICCV | '21 | CV | μ„λ™μ£Ό |
 | [Flamingo: A Visual Language Model for Few-Shot Learning](https://proceedings.neurips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html) | NeurIPS | '22 | NLP | μ΄ν•μ¤€ | 
 | [Mistral AI](https://arxiv.org/pdf/2310.06825.pdf) |  | '23 | NLP | κΉ€μ | [π“](data/Mistral%207B.pdf) |
 | [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084) | EMNLP | '19 | NLP | μ„λ™μ£Ό | 
 | [ODIN: Enhancing the Reliability of Out-of-Distribution Image Detection in Neural Networks](https://arxiv.org/abs/1706.02690) | ICLR | '18 | OOD | κΉ€λ‚ν› | [π“](data/presentation_odin.pdf) | 
 | [Image Style Transfer using Convolutional Neural Networks](https://openaccess.thecvf.com/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html) | CVPR | '16 | CV | μ¤μ„Έν™ |
 | [wav2vec2.0: A Framework for Self-Supervised Learning of Speech Representations](https://proceedings.neurips.cc/paper/2020/hash/92d1e1eb1cd6f9fba3227870bb6d7f07-Abstract.html) | NeurIPS | '20 | SR | κΉ€μ | [π“](data/Wav2vec%202.0.pdf) |
 | [Can Large Language Models Be an Alternative to Human Evaluations?](https://arxiv.org/pdf/2305.01937.pdf) |  | '23 | NLP | μ΄ν•μ¤€ |  |
 | [Neural Speech Synthesis with Transformer Network](https://arxiv.org/pdf/1809.08895.pdf)) | AAAI | '19 | TTS | μ„λ™μ£Ό |  |
 | [λ…Όλ¬Έμ λ©](#) | ν•™ν | 'μ—°λ„ | λ¶„μ•Ό | λ°ν‘μ | λ°ν‘μλ£ | μ°Έκ³ μλ£ |
